HW2 PART1The first word pair randomly chosen is: [¡®boy¡¯, ¡®brother¡¯], similarity: 6.67, line 548The second word pair randomly chosen is: [¡®winner¡¯, ¡®presence¡¯], similarity: 1.08, line 715The third word pair randomly chosen is: [¡®home¡¯, ¡®state¡¯], similarity: 2.58, line 602Sim_Lex999 similarity scores: {pair1: 6.67, pair2: 1.08, pair3: 2.58}Universal encoder cosine similarity: {pair1: 0.57, pair2: 0.29, pair3: 0.56}Word2vec cosine similarity: {pair1: 0.98, pair2: 0.99, pair3: 0.96}Grokking cosine similarity: {pair1: 0.54, pair2: 0.19, pair3: -0.05}Discussion:Based on the data above, we see that the similarity scores from Sim_Lex999 are very different in scale from the other three. This is probably because Sim_Lex999 similarity scores are calculated based on some other mechanisms rather than cosine similarity exactly. Among the three models, the similarity scores calculated based on Universal encoder is the most similar one to that of Sim_Lex999 as the trends of the two are close to each other. Whereas the similarity scores from Word2vec are all very high with almost no fluctuation between values. Lastly, the similarity score for the third word pair from Grokking is negative, which is abnormal because it the score for the third word pair are all positive from the other three. This is probably because ¡®home¡¯ and ¡®state¡¯, which are the two words from the third word pair, are considered hugely opposite to each other in the raw text that we used to train the Grokking model.